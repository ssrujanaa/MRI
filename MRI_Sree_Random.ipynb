{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 235), (1, 50)]\n",
      "199 86\n",
      "0    164\n",
      "1     35\n",
      "Name: Label, dtype: int64 0    71\n",
      "1    15\n",
      "Name: Label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd  \n",
    "from collections import Counter\n",
    "cancer = pd.read_csv(\"MRI_Sree.csv\")\n",
    "cancer['Label'] = cancer['Label'].map({'GBM': 0, 'Recurrent GBM': 1})\n",
    "X, y = cancer.drop(['Patient_ID_x','file'], axis=1), cancer['Label']\n",
    "print(sorted(Counter(y).items()))\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 20,stratify = y)\n",
    "X_test = X_test.drop(['Label'],axis=1)\n",
    "X_train = X_train.drop(['Label'],axis=1)\n",
    "print(len(X_train), len(X_test))\n",
    "print(y_train.value_counts(), y_test.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 164), (1, 35)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(Counter(y_train).items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 164), (1, 164)]\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "ros = RandomOverSampler(random_state=0)\n",
    "X_resampled, y_resampled = ros.fit_resample(X_train, y_train)\n",
    "\n",
    "from collections import Counter\n",
    "print(sorted(Counter(y_resampled).items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of our training \"X\" (input features) is (328, 1199)\n",
      "\n",
      "\n",
      "The size of our testing \"X\" (input features) is (86, 1199)\n",
      "\n",
      "\n",
      "The size of our training \"y\" (output feature) is (328,)\n",
      "\n",
      "\n",
      "The size of our testing \"y\" (output features) is (86,)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.94      0.92        71\n",
      "           1       0.67      0.53      0.59        15\n",
      "\n",
      "    accuracy                           0.87        86\n",
      "   macro avg       0.79      0.74      0.76        86\n",
      "weighted avg       0.86      0.87      0.87        86\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.872093023255814"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_resampled)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "print ('The size of our training \"X\" (input features) is', X_train.shape)\n",
    "print ('\\n')\n",
    "print ('The size of our testing \"X\" (input features) is', X_test.shape)\n",
    "print ('\\n')\n",
    "print ('The size of our training \"y\" (output feature) is', y_resampled.shape)\n",
    "print ('\\n')\n",
    "print ('The size of our testing \"y\" (output features) is', y_test.shape)\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "svc_model = SVC(kernel = 'rbf', random_state = 20)\n",
    "\n",
    "svc_model.fit(X_train, y_resampled)\n",
    "\n",
    "y_predict = svc_model.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "cm = np.array(confusion_matrix(y_test, y_predict, labels=[0,1]))\n",
    "confusion = pd.DataFrame(cm, index=['0', '1'],\n",
    "                         columns=['1','0'])\n",
    "\n",
    "sns.heatmap(confusion, annot=True)\n",
    "\n",
    "print(classification_report(y_test, y_predict))\n",
    "\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_score(y_test, y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'SVC' object has no attribute 'feature_importances_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-4b852d758de0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mimportance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msvc_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_importances_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'SVC' object has no attribute 'feature_importances_'"
     ]
    }
   ],
   "source": [
    "importance = svc_model.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'rfe' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-f361e5c6756d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# get importance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mimportance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrfe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m# # summarize feature importance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# for i,v in enumerate(importance):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#       print('Feature: %0d, Score: %.5f' % (i,v))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'rfe' is not defined"
     ]
    }
   ],
   "source": [
    "# get importance\n",
    "importance = rfe.estimator_.coef_\n",
    "# # summarize feature importance\n",
    "# for i,v in enumerate(importance):\n",
    "# \tprint('Feature: %0d, Score: %.5f' % (i,v))\n",
    "# # plot feature importance\n",
    "# pyplot.bar([x for x in range(len(importance))], importance)\n",
    "# pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.svm import LinearSVC\n",
    "# clf = LinearSVC()\n",
    "# clf.fit(X_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-10-de603c91038f>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-10-de603c91038f>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    ]\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "coef = svc_model.coef_.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def feature_plot(classifier, feature_names, top_features=6):\n",
    "    coef = classifier.coef_.ravel()\n",
    "    top_positive_coefficients = np.argsort(coef)[-top_features:]\n",
    "    top_negative_coefficients = np.argsort(coef)[:top_features]\n",
    "    top_coefficients = np.hstack([top_negative_coefficients, top_positive_coefficients])\n",
    "    plt.figure(figsize=(18, 7))\n",
    "    colors = ['green' if c < 0 else 'blue' for c in coef[top_coefficients]]\n",
    "    plt.bar(np.arange(2 * top_features), coef[top_coefficients], color=colors)\n",
    "    feature_names = np.array(feature_names)\n",
    "    plt.xticks(np.arange(1 + 2 * top_features), feature_names[top_coefficients], rotation=45, ha='right')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "feature_plot(svc_model, cancer.drop(['Label','Patient_ID_x'], axis=1).columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import plot_roc_curve\n",
    "svc_disp = plot_roc_curve(svc_model, X_test, y_test)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "print(\"Random Forest\")\n",
    "print(\"%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\")\n",
    "print(\"%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\")\n",
    "print(\"\\n\")\n",
    "print ('The size of our training \"X\" (input features) is', X_train.shape)\n",
    "print ('\\n')\n",
    "print ('The size of our testing \"X\" (input features) is', X_test.shape)\n",
    "print ('\\n')\n",
    "print ('The size of our training \"y\" (output feature) is', y_train.shape)\n",
    "print ('\\n')\n",
    "print ('The size of our testing \"y\" (output features) is', y_test.shape)\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "# svc_model = RandomForestClassifier(n_estimators = 30, criterion = 'entropy', random_state = 20)\n",
    "svc_model = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=0, n_jobs = -1)\n",
    "svc_model.fit(X_train, y_train)\n",
    "\n",
    "y_predict = svc_model.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "cm = np.array(confusion_matrix(y_test, y_predict, labels=[0,1]))\n",
    "confusion = pd.DataFrame(cm, index=['0', '1'],\n",
    "                         columns=['1','0'])\n",
    "\n",
    "sns.heatmap(confusion, annot=True)\n",
    "\n",
    "print(classification_report(y_test, y_predict))\n",
    "\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_predict))\n",
    "\n",
    "# Model Precision: what percentage of positive tuples are labeled as such?\n",
    "print(\"Precision:\",metrics.precision_score(y_test, y_predict))\n",
    "\n",
    "# Model Recall: what percentage of positive tuples are labelled as such?\n",
    "print(\"Recall:\",metrics.recall_score(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def feature_plot(classifier, feature_names, top_features=6):\n",
    "    coef = classifier.best_estimator_.feature_importances_\n",
    "    top_positive_coefficients = np.argsort(coef)[-top_features:]\n",
    "    top_negative_coefficients = np.argsort(coef)[:top_features]\n",
    "    top_coefficients = np.hstack([top_negative_coefficients, top_positive_coefficients])\n",
    "    plt.figure(figsize=(18, 7))\n",
    "    colors = ['green' if c < 0 else 'blue' for c in coef[top_coefficients]]\n",
    "    plt.bar(np.arange(2 * top_features), coef[top_coefficients], color=colors)\n",
    "    feature_names = np.array(feature_names)\n",
    "    plt.xticks(np.arange(1 + 2 * top_features), feature_names[top_coefficients], rotation=45, ha='right')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "feature_plot(svc_model, cancer.drop(['Label','Patient_ID_x'], axis=1).columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import ensemble\n",
    "from sklearn import metrics\n",
    "\n",
    "%matplotlib inline\n",
    "#Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "print(\"Gradient Boosting\")\n",
    "print(\"%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\")\n",
    "print(\"%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\")\n",
    "print(\"\\n\")\n",
    "print ('The size of our training \"X\" (input features) is', X_train.shape)\n",
    "print ('\\n')\n",
    "print ('The size of our testing \"X\" (input features) is', X_test.shape)\n",
    "print ('\\n')\n",
    "print ('The size of our training \"y\" (output feature) is', y_train.shape)\n",
    "print ('\\n')\n",
    "print ('The size of our testing \"y\" (output features) is', y_test.shape)\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# svc_model = GradientBoostingClassifier()\n",
    "params = {'n_estimators': 1500, 'max_depth': 3, 'subsample': 0.2,\n",
    "          'learning_rate': 0.01, 'min_samples_leaf': 2, 'random_state': 0}\n",
    "svc_model = ensemble.GradientBoostingClassifier(**params)\n",
    "\n",
    "svc_model.fit(X_train, y_train)\n",
    "\n",
    "y_predict = svc_model.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "cm = np.array(confusion_matrix(y_test, y_predict, labels=[0,1]))\n",
    "confusion = pd.DataFrame(cm, index=['0', '1'],\n",
    "                         columns=['1','0'])\n",
    "\n",
    "sns.heatmap(confusion, annot=True)\n",
    "\n",
    "print(classification_report(y_test, y_predict))\n",
    "\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_predict))\n",
    "\n",
    "# Model Precision: what percentage of positive tuples are labeled as such?\n",
    "print(\"Precision:\",metrics.precision_score(y_test, y_predict))\n",
    "\n",
    "# Model Recall: what percentage of positive tuples are labelled as such?\n",
    "print(\"Recall:\",metrics.recall_score(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
