{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 235), (1, 50)]\n",
      "199 86\n",
      "0    164\n",
      "1     35\n",
      "Name: Label, dtype: int64 0    71\n",
      "1    15\n",
      "Name: Label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd  \n",
    "from collections import Counter\n",
    "cancer = pd.read_csv(\"MRI_Sree.csv\")\n",
    "cancer['Label'] = cancer['Label'].map({'GBM': 0, 'Recurrent GBM': 1})\n",
    "X, y = cancer.drop(['Patient_ID_x','file'], axis=1), cancer['Label']\n",
    "print(sorted(Counter(y).items()))\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 20,stratify = y)\n",
    "X_test = X_test.drop(['Label'],axis=1)\n",
    "X_train = X_train.drop(['Label'],axis=1)\n",
    "print(len(X_train), len(X_test))\n",
    "print(y_train.value_counts(), y_test.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 164), (1, 164)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.svm import LinearSVC\n",
    "# clf = LinearSVC()\n",
    "sm = SMOTE(random_state=0)\n",
    "X_resampled, y_resampled = sm.fit_resample(X_train, y_train)\n",
    "print(sorted(Counter(y_resampled).items()))\n",
    "clf_smote = LinearSVC().fit(X_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of our training \"X\" (input features) is (328, 1199)\n",
      "\n",
      "\n",
      "The size of our testing \"X\" (input features) is (86, 1199)\n",
      "\n",
      "\n",
      "The size of our training \"y\" (output feature) is (328,)\n",
      "\n",
      "\n",
      "The size of our testing \"y\" (output features) is (86,)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.92      0.92        71\n",
      "           1       0.62      0.67      0.65        15\n",
      "\n",
      "    accuracy                           0.87        86\n",
      "   macro avg       0.78      0.79      0.78        86\n",
      "weighted avg       0.88      0.87      0.87        86\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.872093023255814"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_resampled)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "print ('The size of our training \"X\" (input features) is', X_train.shape)\n",
    "print ('\\n')\n",
    "print ('The size of our testing \"X\" (input features) is', X_test.shape)\n",
    "print ('\\n')\n",
    "print ('The size of our training \"y\" (output feature) is', y_resampled.shape)\n",
    "print ('\\n')\n",
    "print ('The size of our testing \"y\" (output features) is', y_test.shape)\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "svc_model = SVC(kernel = 'rbf', random_state = 20)\n",
    "\n",
    "svc_model.fit(X_train, y_resampled)\n",
    "\n",
    "y_predict = svc_model.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "cm = np.array(confusion_matrix(y_test, y_predict, labels=[0,1]))\n",
    "confusion = pd.DataFrame(cm, index=['0', '1'],\n",
    "                         columns=['1','0'])\n",
    "\n",
    "sns.heatmap(confusion, annot=True)\n",
    "\n",
    "print(classification_report(y_test, y_predict))\n",
    "\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_score(y_test, y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "print(\"Random Forest\")\n",
    "print(\"%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\")\n",
    "print(\"%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\")\n",
    "print(\"\\n\")\n",
    "print ('The size of our training \"X\" (input features) is', X_train.shape)\n",
    "print ('\\n')\n",
    "print ('The size of our testing \"X\" (input features) is', X_test.shape)\n",
    "print ('\\n')\n",
    "print ('The size of our training \"y\" (output feature) is', y_train.shape)\n",
    "print ('\\n')\n",
    "print ('The size of our testing \"y\" (output features) is', y_test.shape)\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "# svc_model = RandomForestClassifier(n_estimators = 30, criterion = 'entropy', random_state = 20)\n",
    "svc_model = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=0, n_jobs = -1)\n",
    "svc_model.fit(X_train, y_train)\n",
    "\n",
    "y_predict = svc_model.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "cm = np.array(confusion_matrix(y_test, y_predict, labels=[0,1]))\n",
    "confusion = pd.DataFrame(cm, index=['0', '1'],\n",
    "                         columns=['1','0'])\n",
    "\n",
    "sns.heatmap(confusion, annot=True)\n",
    "\n",
    "print(classification_report(y_test, y_predict))\n",
    "\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_predict))\n",
    "\n",
    "# Model Precision: what percentage of positive tuples are labeled as such?\n",
    "print(\"Precision:\",metrics.precision_score(y_test, y_predict))\n",
    "\n",
    "# Model Recall: what percentage of positive tuples are labelled as such?\n",
    "print(\"Recall:\",metrics.recall_score(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import ensemble\n",
    "from sklearn import metrics\n",
    "\n",
    "%matplotlib inline\n",
    "#Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "print(\"Gradient Boosting\")\n",
    "print(\"%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\")\n",
    "print(\"%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\")\n",
    "print(\"\\n\")\n",
    "print ('The size of our training \"X\" (input features) is', X_train.shape)\n",
    "print ('\\n')\n",
    "print ('The size of our testing \"X\" (input features) is', X_test.shape)\n",
    "print ('\\n')\n",
    "print ('The size of our training \"y\" (output feature) is', y_train.shape)\n",
    "print ('\\n')\n",
    "print ('The size of our testing \"y\" (output features) is', y_test.shape)\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# svc_model = GradientBoostingClassifier()\n",
    "params = {'n_estimators': 1500, 'max_depth': 3, 'subsample': 0.2,\n",
    "          'learning_rate': 0.01, 'min_samples_leaf': 2, 'random_state': 0}\n",
    "svc_model = ensemble.GradientBoostingClassifier(**params)\n",
    "\n",
    "svc_model.fit(X_train, y_train)\n",
    "\n",
    "y_predict = svc_model.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "cm = np.array(confusion_matrix(y_test, y_predict, labels=[0,1]))\n",
    "confusion = pd.DataFrame(cm, index=['0', '1'],\n",
    "                         columns=['1','0'])\n",
    "\n",
    "sns.heatmap(confusion, annot=True)\n",
    "\n",
    "print(classification_report(y_test, y_predict))\n",
    "\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_predict))\n",
    "\n",
    "# Model Precision: what percentage of positive tuples are labeled as such?\n",
    "print(\"Precision:\",metrics.precision_score(y_test, y_predict))\n",
    "\n",
    "# Model Recall: what percentage of positive tuples are labelled as such?\n",
    "print(\"Recall:\",metrics.recall_score(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
